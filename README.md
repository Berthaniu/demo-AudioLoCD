## SoundLoCD: An Efficient Conditional Discrete Contrastive Latent Diffusion Model for Text-to-Sound Generation

### About 

This is a [demo](https://Berthaniu.github.io/demo-AudioLoCD/) for our [paper](https://Berthaniu.github.io/demo-AudioLoCD/) 'SoundLoCD: An Efficient Conditional Discrete Contrastive Latent Diffusion Model for Text-to-Sound Generation_'. The SoundLoCD is a LoRA-based conditional discrete contrastive latent diffusion model for text-to-sound effects generation. Unlike recent large-scale audio generation models, our SoundLoCD can be efficiently trained under limited computational resources. The integration of a contrastive learning strategy enhances the connection between textual conditions and the generated audio outputs, resulting in coherent performance. 

### Citation

If you are interesting in our work, please cite it as below:

```
@INPROCEEDINGS{niu2023audiolocd,
  author={Niu, Xinlei, Jing Zhang, Christian Walder, and Charles Patrick Martin}
  title={SoundLoCD: An Efficient Conditional Discrete Contrastive Latent Diffusion Model for Text-to-Sound Generation}, 
  year={2023}
}
```